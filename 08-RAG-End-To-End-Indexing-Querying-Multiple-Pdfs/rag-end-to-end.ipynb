{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieval augmented generation\n",
    "\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # take environment variables from .env (especially openai api key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\") # set api key from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import  VectorStoreIndex, SimpleDirectoryReader\n",
    "documents = SimpleDirectoryReader('pdf').load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='764722bf-0534-4cec-896c-afd4710bd188', embedding=None, metadata={'page_label': '1', 'file_name': 'test.pdf', 'file_path': 'pdf\\\\test.pdf', 'file_type': 'application/pdf', 'file_size': 59227, 'creation_date': '2024-01-11', 'last_modified_date': '2024-01-11', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Note: this is the 2017 version of this assignment.\\nIn this assignment you will practice putting together a simple image classification pipeline,\\nbased on the k-Nearest Neighbor or the SVM/Softmax classifier. The goals of this\\nassignment are as follows:\\n\\uf0b7understand the basic Image Classification pipeline  and the data-driven approach \\n(train/predict stages)\\n\\uf0b7understand the train/val/test splits  and the use of validation data \\nfor hyperparameter tuning .\\n\\uf0b7develop proficiency in writing efficient vectorized  code with numpy\\n\\uf0b7implement and apply a k-Nearest Neighbor ( kNN) classifier\\n\\uf0b7implement and apply a Multiclass Support Vector Machine ( SVM ) classifier\\n\\uf0b7implement and apply a Softmax  classifier\\n\\uf0b7implement and apply a Two layer neural network  classifier\\n\\uf0b7understand the differences and tradeoffs between these classifiers\\n\\uf0b7get a basic understanding of performance improvements from using higher-level \\nrepresentations  than raw pixels (e.g. color histograms, Histogram of Gradient \\n(HOG) features)\\nSetup\\nYou can work on the assignment in one of two ways: locally on your own machine, or on a\\nvirtual machine on Google Cloud.\\nWorking remotely on Google Cloud (Recommended)\\nNote:  after following these instructions, make sure you go to Download data  below (you\\ncan skip the Working locally  section).\\nAs part of this course, you can use Google Cloud for your assignments. We recommend\\nthis route for anyone who is having trouble with installation set-up, or if you would like to\\nuse better CPU/GPU resources than you may have locally. Please see the set-up\\ntutorial here for more details. :)\\nWorking locally\\nGet the code as a zip file here. As for the dependencies:\\nInstalling Python 3.5+:  To use python3, make sure to install version 3.5 or 3.6 on your\\nlocal machine. If you are on Mac OS X, you can do this using Homebrew  with brew\\ninstall python3 . You can find instructions for Ubuntu here.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='68a95675-791b-42f8-b2f2-9172e6f09d45', embedding=None, metadata={'page_label': '2', 'file_name': 'test.pdf', 'file_path': 'pdf\\\\test.pdf', 'file_type': 'application/pdf', 'file_size': 59227, 'creation_date': '2024-01-11', 'last_modified_date': '2024-01-11', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Virtual environment:  If you decide to work locally, we recommend using virtual\\nenvironment  for the project. If you choose not to use a virtual environment, it is up to you\\nto make sure that all dependencies for the code are installed globally on your machine.\\nTo set up a virtual environment, run the following:\\ncd assignment1\\nsudo pip install virtualenv      # This may already be installed\\nvirtualenv -p python3 .env       # Create a virtual environment \\n(python3)\\n# Note: you can also use \"virtualenv .env\" to use your default \\npython (usually python 2.7)\\nsource .env/bin/activate         # Activate the virtual environment\\npip install -r requirements.txt  # Install dependencies\\n# Work on the assignment for a while ...\\ndeactivate                       # Exit the virtual environment\\nNote that every time you want to work on the assignment, you should run source\\n.env/bin/activate  (from within your assignment1  folder) to re-activate the virtual\\nenvironment, and deactivate  again whenever you are done.\\nDownload data:\\nOnce you have the starter code (regardless of which method you choose above), you will\\nneed to download the CIFAR-10 dataset. Run the following from\\nthe assignment1  directory:\\ncd cs231n/datasets\\n./get_datasets.sh\\nStart IPython:\\nAfter you have the CIFAR-10 data, you should start the IPython notebook server from\\nthe assignment1  directory, with the jupyter notebook  command. (See the Google\\nCloud Tutorial  for any additional steps you may need to do for setting this up, if you are\\nworking remotely)\\nIf you are unfamiliar with IPython, you can also refer to our IPython tutorial .\\nSome Notes\\nNOTE 1:  This year, the assignment1  code has been tested to be compatible with\\npython versions 2.7, 3.5, 3.6 (it may work with other versions of 3.x, but we won’t be', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='bab30619-4a09-4e59-84d9-f029d148d4be', embedding=None, metadata={'page_label': '3', 'file_name': 'test.pdf', 'file_path': 'pdf\\\\test.pdf', 'file_type': 'application/pdf', 'file_size': 59227, 'creation_date': '2024-01-11', 'last_modified_date': '2024-01-11', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='officially supporting them). You will need to make sure that during\\nyour virtualenv  setup that the correct version of python  is used. You can confirm your\\npython version by (1) activating your virtualenv and (2) running which python .\\nNOTE 2:  If you are working in a virtual environment on OSX, you\\nmay potentially  encounter errors with matplotlib due to the issues described here . In our\\ntesting, it seems that this issue is no longer present with the most recent version of\\nmatplotlib, but if you do end up running into this issue you may have to use\\nthe start_ipython_osx.sh  script from the assignment1  directory (instead\\nof jupyter notebook  above) to launch your IPython notebook server. Note that you\\nmay have to modify some variables within the script to match your version of\\npython/installation directory. The script assumes that your virtual environment is\\nnamed .env .\\nSubmitting your work:\\nWhether you work on the assignment locally or using Google Cloud, once you are done\\nworking run the collectSubmission.sh  script; this will produce a file\\ncalled assignment1.zip . Please submit this file on Canvas .\\nQ1: k-Nearest Neighbor classifier (20 points)\\nThe IPython Notebook knn.ipynb  will walk you through implementing the kNN classifier.\\nQ2: Training a Support Vector Machine (25 points)\\nThe IPython Notebook svm.ipynb  will walk you through implementing the SVM classifier.\\nQ3: Implement a Softmax classifier (20 points)\\nThe IPython Notebook softmax.ipynb  will walk you through implementing the Softmax\\nclassifier.\\nQ4: Two-Layer Neural Network (25 points)\\nThe IPython Notebook two_layer_net.ipynb  will walk you through the implementation of\\na two-layer neural network classifier.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6ea0f42c-3dc6-46b3-8703-06869a5f70ce', embedding=None, metadata={'page_label': '4', 'file_name': 'test.pdf', 'file_path': 'pdf\\\\test.pdf', 'file_type': 'application/pdf', 'file_size': 59227, 'creation_date': '2024-01-11', 'last_modified_date': '2024-01-11', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Q5: Higher Level Representations: Image Features (10 \\npoints)\\nThe IPython Notebook features.ipynb  will walk you through this exercise, in which you\\nwill examine the improvements gained by using higher-level representations as opposed\\nto using raw pixel values.\\nQ6: Cool Bonus: Do something extra! (+10 points)\\nImplement, investigate or analyze something extra surrounding the topics in this\\nassignment, and using the code you developed. For example, is there some other\\ninteresting question we could have asked? Is there any insightful visualization you can\\nplot? Or anything fun to look at? Or maybe you can experiment with a spin on the loss\\nfunction? If you try out something cool we’ll give you up to 10 extra points and may\\nfeature your results in the lecture.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\artificial-intelegnce\\courses\\Learn LangChain In 1 Hour With End To End LLM Project With Deployment In Huggingface Spaces\\github\\LangchainEndtoEnd\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Parsing nodes: 100%|██████████| 4/4 [00:00<00:00, 877.97it/s]\n",
      "Generating embeddings:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mf:\\artificial-intelegnce\\courses\\Learn LangChain In 1 Hour With End To End LLM Project With Deployment In Huggingface Spaces\\github\\LangchainEndtoEnd\\08-RAG-End-To-End-Indexing-Querying-Multiple-Pdfs\\rag-end-to-end.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/artificial-intelegnce/courses/Learn%20LangChain%20In%201%20Hour%20With%20End%20To%20End%20LLM%20Project%20With%20Deployment%20In%20Huggingface%20Spaces/github/LangchainEndtoEnd/08-RAG-End-To-End-Indexing-Querying-Multiple-Pdfs/rag-end-to-end.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m index \u001b[39m=\u001b[39m VectorStoreIndex\u001b[39m.\u001b[39;49mfrom_documents(documents, show_progress\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mf:\\artificial-intelegnce\\courses\\Learn LangChain In 1 Hour With End To End LLM Project With Deployment In Huggingface Spaces\\github\\LangchainEndtoEnd\\venv\\lib\\site-packages\\llama_index\\indices\\base.py:112\u001b[0m, in \u001b[0;36mBaseIndex.from_documents\u001b[1;34m(cls, documents, storage_context, service_context, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m     docstore\u001b[39m.\u001b[39mset_document_hash(doc\u001b[39m.\u001b[39mget_doc_id(), doc\u001b[39m.\u001b[39mhash)\n\u001b[0;32m    105\u001b[0m nodes \u001b[39m=\u001b[39m run_transformations(\n\u001b[0;32m    106\u001b[0m     documents,  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[0;32m    107\u001b[0m     service_context\u001b[39m.\u001b[39mtransformations,\n\u001b[0;32m    108\u001b[0m     show_progress\u001b[39m=\u001b[39mshow_progress,\n\u001b[0;32m    109\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    110\u001b[0m )\n\u001b[1;32m--> 112\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(\n\u001b[0;32m    113\u001b[0m     nodes\u001b[39m=\u001b[39mnodes,\n\u001b[0;32m    114\u001b[0m     storage_context\u001b[39m=\u001b[39mstorage_context,\n\u001b[0;32m    115\u001b[0m     service_context\u001b[39m=\u001b[39mservice_context,\n\u001b[0;32m    116\u001b[0m     show_progress\u001b[39m=\u001b[39mshow_progress,\n\u001b[0;32m    117\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    118\u001b[0m )\n",
      "File \u001b[1;32mf:\\artificial-intelegnce\\courses\\Learn LangChain In 1 Hour With End To End LLM Project With Deployment In Huggingface Spaces\\github\\LangchainEndtoEnd\\venv\\lib\\site-packages\\llama_index\\indices\\vector_store\\base.py:53\u001b[0m, in \u001b[0;36mVectorStoreIndex.__init__\u001b[1;34m(self, nodes, objects, index_struct, service_context, storage_context, use_async, store_nodes_override, insert_batch_size, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_store_nodes_override \u001b[39m=\u001b[39m store_nodes_override\n\u001b[0;32m     52\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_insert_batch_size \u001b[39m=\u001b[39m insert_batch_size\n\u001b[1;32m---> 53\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[0;32m     54\u001b[0m     nodes\u001b[39m=\u001b[39mnodes,\n\u001b[0;32m     55\u001b[0m     index_struct\u001b[39m=\u001b[39mindex_struct,\n\u001b[0;32m     56\u001b[0m     service_context\u001b[39m=\u001b[39mservice_context,\n\u001b[0;32m     57\u001b[0m     storage_context\u001b[39m=\u001b[39mstorage_context,\n\u001b[0;32m     58\u001b[0m     show_progress\u001b[39m=\u001b[39mshow_progress,\n\u001b[0;32m     59\u001b[0m     objects\u001b[39m=\u001b[39mobjects,\n\u001b[0;32m     60\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m     61\u001b[0m )\n",
      "File \u001b[1;32mf:\\artificial-intelegnce\\courses\\Learn LangChain In 1 Hour With End To End LLM Project With Deployment In Huggingface Spaces\\github\\LangchainEndtoEnd\\venv\\lib\\site-packages\\llama_index\\indices\\base.py:75\u001b[0m, in \u001b[0;36mBaseIndex.__init__\u001b[1;34m(self, nodes, objects, index_struct, storage_context, service_context, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[39mif\u001b[39;00m index_struct \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     nodes \u001b[39m=\u001b[39m nodes \u001b[39mor\u001b[39;00m []\n\u001b[1;32m---> 75\u001b[0m     index_struct \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuild_index_from_nodes(\n\u001b[0;32m     76\u001b[0m         nodes \u001b[39m+\u001b[39;49m objects  \u001b[39m# type: ignore\u001b[39;49;00m\n\u001b[0;32m     77\u001b[0m     )\n\u001b[0;32m     78\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_struct \u001b[39m=\u001b[39m index_struct\n\u001b[0;32m     79\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_storage_context\u001b[39m.\u001b[39mindex_store\u001b[39m.\u001b[39madd_index_struct(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_struct)\n",
      "File \u001b[1;32mf:\\artificial-intelegnce\\courses\\Learn LangChain In 1 Hour With End To End LLM Project With Deployment In Huggingface Spaces\\github\\LangchainEndtoEnd\\venv\\lib\\site-packages\\llama_index\\indices\\vector_store\\base.py:274\u001b[0m, in \u001b[0;36mVectorStoreIndex.build_index_from_nodes\u001b[1;34m(self, nodes, **insert_kwargs)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(\n\u001b[0;32m    267\u001b[0m     node\u001b[39m.\u001b[39mget_content(metadata_mode\u001b[39m=\u001b[39mMetadataMode\u001b[39m.\u001b[39mEMBED) \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m node \u001b[39min\u001b[39;00m nodes\n\u001b[0;32m    268\u001b[0m ):\n\u001b[0;32m    269\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    270\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot build index from nodes with no content. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    271\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease ensure all nodes have content.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    272\u001b[0m     )\n\u001b[1;32m--> 274\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_index_from_nodes(nodes, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39minsert_kwargs)\n",
      "File \u001b[1;32mf:\\artificial-intelegnce\\courses\\Learn LangChain In 1 Hour With End To End LLM Project With Deployment In Huggingface Spaces\\github\\LangchainEndtoEnd\\venv\\lib\\site-packages\\llama_index\\indices\\vector_store\\base.py:246\u001b[0m, in \u001b[0;36mVectorStoreIndex._build_index_from_nodes\u001b[1;34m(self, nodes, **insert_kwargs)\u001b[0m\n\u001b[0;32m    244\u001b[0m     run_async_tasks(tasks)\n\u001b[0;32m    245\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 246\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_add_nodes_to_index(\n\u001b[0;32m    247\u001b[0m         index_struct,\n\u001b[0;32m    248\u001b[0m         nodes,\n\u001b[0;32m    249\u001b[0m         show_progress\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_show_progress,\n\u001b[0;32m    250\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39minsert_kwargs,\n\u001b[0;32m    251\u001b[0m     )\n\u001b[0;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m index_struct\n",
      "File \u001b[1;32mf:\\artificial-intelegnce\\courses\\Learn LangChain In 1 Hour With End To End LLM Project With Deployment In Huggingface Spaces\\github\\LangchainEndtoEnd\\venv\\lib\\site-packages\\llama_index\\indices\\vector_store\\base.py:199\u001b[0m, in \u001b[0;36mVectorStoreIndex._add_nodes_to_index\u001b[1;34m(self, index_struct, nodes, show_progress, **insert_kwargs)\u001b[0m\n\u001b[0;32m    196\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39mfor\u001b[39;00m nodes_batch \u001b[39min\u001b[39;00m iter_batch(nodes, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_insert_batch_size):\n\u001b[1;32m--> 199\u001b[0m     nodes_batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_node_with_embedding(nodes_batch, show_progress)\n\u001b[0;32m    200\u001b[0m     new_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vector_store\u001b[39m.\u001b[39madd(nodes_batch, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39minsert_kwargs)\n\u001b[0;32m    202\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vector_store\u001b[39m.\u001b[39mstores_text \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_store_nodes_override:\n\u001b[0;32m    203\u001b[0m         \u001b[39m# NOTE: if the vector store doesn't store text,\u001b[39;00m\n\u001b[0;32m    204\u001b[0m         \u001b[39m# we need to add the nodes to the index struct and document store\u001b[39;00m\n",
      "File \u001b[1;32mf:\\artificial-intelegnce\\courses\\Learn LangChain In 1 Hour With End To End LLM Project With Deployment In Huggingface Spaces\\github\\LangchainEndtoEnd\\venv\\lib\\site-packages\\llama_index\\indices\\vector_store\\base.py:107\u001b[0m, in \u001b[0;36mVectorStoreIndex._get_node_with_embedding\u001b[1;34m(self, nodes, show_progress)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_node_with_embedding\u001b[39m(\n\u001b[0;32m     97\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     98\u001b[0m     nodes: Sequence[BaseNode],\n\u001b[0;32m     99\u001b[0m     show_progress: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    100\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[BaseNode]:\n\u001b[0;32m    101\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get tuples of id, node, and embedding.\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \n\u001b[0;32m    103\u001b[0m \u001b[39m    Allows us to store these nodes in a vector store.\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[39m    Embeddings are called in batches.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 107\u001b[0m     id_to_embed_map \u001b[39m=\u001b[39m embed_nodes(\n\u001b[0;32m    108\u001b[0m         nodes, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_service_context\u001b[39m.\u001b[39;49membed_model, show_progress\u001b[39m=\u001b[39;49mshow_progress\n\u001b[0;32m    109\u001b[0m     )\n\u001b[0;32m    111\u001b[0m     results \u001b[39m=\u001b[39m []\n\u001b[0;32m    112\u001b[0m     \u001b[39mfor\u001b[39;00m node \u001b[39min\u001b[39;00m nodes:\n",
      "File \u001b[1;32mf:\\artificial-intelegnce\\courses\\Learn LangChain In 1 Hour With End To End LLM Project With Deployment In Huggingface Spaces\\github\\LangchainEndtoEnd\\venv\\lib\\site-packages\\llama_index\\indices\\utils.py:137\u001b[0m, in \u001b[0;36membed_nodes\u001b[1;34m(nodes, embed_model, show_progress)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    135\u001b[0m         id_to_embed_map[node\u001b[39m.\u001b[39mnode_id] \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39membedding\n\u001b[1;32m--> 137\u001b[0m new_embeddings \u001b[39m=\u001b[39m embed_model\u001b[39m.\u001b[39;49mget_text_embedding_batch(\n\u001b[0;32m    138\u001b[0m     texts_to_embed, show_progress\u001b[39m=\u001b[39;49mshow_progress\n\u001b[0;32m    139\u001b[0m )\n\u001b[0;32m    141\u001b[0m \u001b[39mfor\u001b[39;00m new_id, text_embedding \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(ids_to_embed, new_embeddings):\n\u001b[0;32m    142\u001b[0m     id_to_embed_map[new_id] \u001b[39m=\u001b[39m text_embedding\n",
      "File \u001b[1;32mf:\\artificial-intelegnce\\courses\\Learn LangChain In 1 Hour With End To End LLM Project With Deployment In Huggingface Spaces\\github\\LangchainEndtoEnd\\venv\\lib\\site-packages\\llama_index\\core\\embeddings\\base.py:256\u001b[0m, in \u001b[0;36mBaseEmbedding.get_text_embedding_batch\u001b[1;34m(self, texts, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[39mif\u001b[39;00m idx \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(texts) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(cur_batch) \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_batch_size:\n\u001b[0;32m    251\u001b[0m     \u001b[39m# flush\u001b[39;00m\n\u001b[0;32m    252\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mevent(\n\u001b[0;32m    253\u001b[0m         CBEventType\u001b[39m.\u001b[39mEMBEDDING,\n\u001b[0;32m    254\u001b[0m         payload\u001b[39m=\u001b[39m{EventPayload\u001b[39m.\u001b[39mSERIALIZED: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_dict()},\n\u001b[0;32m    255\u001b[0m     ) \u001b[39mas\u001b[39;00m event:\n\u001b[1;32m--> 256\u001b[0m         embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_text_embeddings(cur_batch)\n\u001b[0;32m    257\u001b[0m         result_embeddings\u001b[39m.\u001b[39mextend(embeddings)\n\u001b[0;32m    258\u001b[0m         event\u001b[39m.\u001b[39mon_end(\n\u001b[0;32m    259\u001b[0m             payload\u001b[39m=\u001b[39m{\n\u001b[0;32m    260\u001b[0m                 EventPayload\u001b[39m.\u001b[39mCHUNKS: cur_batch,\n\u001b[0;32m    261\u001b[0m                 EventPayload\u001b[39m.\u001b[39mEMBEDDINGS: embeddings,\n\u001b[0;32m    262\u001b[0m             },\n\u001b[0;32m    263\u001b[0m         )\n",
      "File \u001b[1;32mf:\\artificial-intelegnce\\courses\\Learn LangChain In 1 Hour With End To End LLM Project With Deployment In Huggingface Spaces\\github\\LangchainEndtoEnd\\venv\\lib\\site-packages\\llama_index\\embeddings\\openai.py:413\u001b[0m, in \u001b[0;36mOpenAIEmbedding._get_text_embeddings\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Get text embeddings.\u001b[39;00m\n\u001b[0;32m    407\u001b[0m \n\u001b[0;32m    408\u001b[0m \u001b[39mBy default, this is a wrapper around _get_text_embedding.\u001b[39;00m\n\u001b[0;32m    409\u001b[0m \u001b[39mCan be overridden for batch queries.\u001b[39;00m\n\u001b[0;32m    410\u001b[0m \n\u001b[0;32m    411\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    412\u001b[0m client \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_client()\n\u001b[1;32m--> 413\u001b[0m \u001b[39mreturn\u001b[39;00m get_embeddings(\n\u001b[0;32m    414\u001b[0m     client,\n\u001b[0;32m    415\u001b[0m     texts,\n\u001b[0;32m    416\u001b[0m     engine\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_text_engine,\n\u001b[0;32m    417\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39madditional_kwargs,\n\u001b[0;32m    418\u001b[0m )\n",
      "File \u001b[1;32mf:\\artificial-intelegnce\\courses\\Learn LangChain In 1 Hour With End To End LLM Project With Deployment In Huggingface Spaces\\github\\LangchainEndtoEnd\\venv\\lib\\site-packages\\tenacity\\__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[1;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(f, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n",
      "File \u001b[1;32mf:\\artificial-intelegnce\\courses\\Learn LangChain In 1 Hour With End To End LLM Project With Deployment In Huggingface Spaces\\github\\LangchainEndtoEnd\\venv\\lib\\site-packages\\tenacity\\__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[0;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mf:\\artificial-intelegnce\\courses\\Learn LangChain In 1 Hour With End To End LLM Project With Deployment In Huggingface Spaces\\github\\LangchainEndtoEnd\\venv\\lib\\site-packages\\tenacity\\__init__.py:325\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    323\u001b[0m     retry_exc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry_error_cls(fut)\n\u001b[0;32m    324\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreraise:\n\u001b[1;32m--> 325\u001b[0m         \u001b[39mraise\u001b[39;00m retry_exc\u001b[39m.\u001b[39;49mreraise()\n\u001b[0;32m    326\u001b[0m     \u001b[39mraise\u001b[39;00m retry_exc \u001b[39mfrom\u001b[39;00m \u001b[39mfut\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexception\u001b[39;00m()\n\u001b[0;32m    328\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait:\n",
      "File \u001b[1;32mf:\\artificial-intelegnce\\courses\\Learn LangChain In 1 Hour With End To End LLM Project With Deployment In Huggingface Spaces\\github\\LangchainEndtoEnd\\venv\\lib\\site-packages\\tenacity\\__init__.py:158\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreraise\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mNoReturn:\n\u001b[0;32m    157\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_attempt\u001b[39m.\u001b[39mfailed:\n\u001b[1;32m--> 158\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlast_attempt\u001b[39m.\u001b[39;49mresult()\n\u001b[0;32m    159\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mf:\\artificial-intelegnce\\courses\\Learn LangChain In 1 Hour With End To End LLM Project With Deployment In Huggingface Spaces\\github\\LangchainEndtoEnd\\venv\\lib\\concurrent\\futures\\_base.py:433\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    432\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 433\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[0;32m    435\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[0;32m    437\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mf:\\artificial-intelegnce\\courses\\Learn LangChain In 1 Hour With End To End LLM Project With Deployment In Huggingface Spaces\\github\\LangchainEndtoEnd\\venv\\lib\\concurrent\\futures\\_base.py:389\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__get_result\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m--> 389\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    390\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    391\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n",
      "File \u001b[1;32mf:\\artificial-intelegnce\\courses\\Learn LangChain In 1 Hour With End To End LLM Project With Deployment In Huggingface Spaces\\github\\LangchainEndtoEnd\\venv\\lib\\site-packages\\tenacity\\__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[0;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mf:\\artificial-intelegnce\\courses\\Learn LangChain In 1 Hour With End To End LLM Project With Deployment In Huggingface Spaces\\github\\LangchainEndtoEnd\\venv\\lib\\site-packages\\llama_index\\embeddings\\openai.py:178\u001b[0m, in \u001b[0;36mget_embeddings\u001b[1;34m(client, list_of_text, engine, **kwargs)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(list_of_text) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2048\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mThe batch size should not be larger than 2048.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    176\u001b[0m list_of_text \u001b[39m=\u001b[39m [text\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m list_of_text]\n\u001b[1;32m--> 178\u001b[0m data \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39membeddings\u001b[39m.\u001b[39mcreate(\u001b[39minput\u001b[39m\u001b[39m=\u001b[39mlist_of_text, model\u001b[39m=\u001b[39mengine, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\u001b[39m.\u001b[39mdata\n\u001b[0;32m    179\u001b[0m \u001b[39mreturn\u001b[39;00m [d\u001b[39m.\u001b[39membedding \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m data]\n",
      "File \u001b[1;32mf:\\artificial-intelegnce\\courses\\Learn LangChain In 1 Hour With End To End LLM Project With Deployment In Huggingface Spaces\\github\\LangchainEndtoEnd\\venv\\lib\\site-packages\\openai\\resources\\embeddings.py:113\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[1;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    107\u001b[0m         embedding\u001b[39m.\u001b[39membedding \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfrombuffer(  \u001b[39m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[0;32m    108\u001b[0m             base64\u001b[39m.\u001b[39mb64decode(data), dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfloat32\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    109\u001b[0m         )\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m    111\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\n\u001b[1;32m--> 113\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post(\n\u001b[0;32m    114\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39m/embeddings\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    115\u001b[0m     body\u001b[39m=\u001b[39;49mmaybe_transform(params, embedding_create_params\u001b[39m.\u001b[39;49mEmbeddingCreateParams),\n\u001b[0;32m    116\u001b[0m     options\u001b[39m=\u001b[39;49mmake_request_options(\n\u001b[0;32m    117\u001b[0m         extra_headers\u001b[39m=\u001b[39;49mextra_headers,\n\u001b[0;32m    118\u001b[0m         extra_query\u001b[39m=\u001b[39;49mextra_query,\n\u001b[0;32m    119\u001b[0m         extra_body\u001b[39m=\u001b[39;49mextra_body,\n\u001b[0;32m    120\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    121\u001b[0m         post_parser\u001b[39m=\u001b[39;49mparser,\n\u001b[0;32m    122\u001b[0m     ),\n\u001b[0;32m    123\u001b[0m     cast_to\u001b[39m=\u001b[39;49mCreateEmbeddingResponse,\n\u001b[0;32m    124\u001b[0m )\n",
      "File \u001b[1;32mf:\\artificial-intelegnce\\courses\\Learn LangChain In 1 Hour With End To End LLM Project With Deployment In Huggingface Spaces\\github\\LangchainEndtoEnd\\venv\\lib\\site-packages\\openai\\_base_client.py:1180\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1166\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\n\u001b[0;32m   1167\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1168\u001b[0m     path: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1175\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1176\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[0;32m   1177\u001b[0m     opts \u001b[39m=\u001b[39m FinalRequestOptions\u001b[39m.\u001b[39mconstruct(\n\u001b[0;32m   1178\u001b[0m         method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url\u001b[39m=\u001b[39mpath, json_data\u001b[39m=\u001b[39mbody, files\u001b[39m=\u001b[39mto_httpx_files(files), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions\n\u001b[0;32m   1179\u001b[0m     )\n\u001b[1;32m-> 1180\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(ResponseT, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(cast_to, opts, stream\u001b[39m=\u001b[39;49mstream, stream_cls\u001b[39m=\u001b[39;49mstream_cls))\n",
      "File \u001b[1;32mf:\\artificial-intelegnce\\courses\\Learn LangChain In 1 Hour With End To End LLM Project With Deployment In Huggingface Spaces\\github\\LangchainEndtoEnd\\venv\\lib\\site-packages\\openai\\_base_client.py:869\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    860\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    861\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    862\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    867\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    868\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[1;32m--> 869\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[0;32m    870\u001b[0m         cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[0;32m    871\u001b[0m         options\u001b[39m=\u001b[39;49moptions,\n\u001b[0;32m    872\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    873\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    874\u001b[0m         remaining_retries\u001b[39m=\u001b[39;49mremaining_retries,\n\u001b[0;32m    875\u001b[0m     )\n",
      "File \u001b[1;32mf:\\artificial-intelegnce\\courses\\Learn LangChain In 1 Hour With End To End LLM Project With Deployment In Huggingface Spaces\\github\\LangchainEndtoEnd\\venv\\lib\\site-packages\\openai\\_base_client.py:945\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    943\u001b[0m \u001b[39mif\u001b[39;00m retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_retry(err\u001b[39m.\u001b[39mresponse):\n\u001b[0;32m    944\u001b[0m     err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mclose()\n\u001b[1;32m--> 945\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retry_request(\n\u001b[0;32m    946\u001b[0m         options,\n\u001b[0;32m    947\u001b[0m         cast_to,\n\u001b[0;32m    948\u001b[0m         retries,\n\u001b[0;32m    949\u001b[0m         err\u001b[39m.\u001b[39;49mresponse\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    950\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    951\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    952\u001b[0m     )\n\u001b[0;32m    954\u001b[0m \u001b[39m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m    955\u001b[0m \u001b[39m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m    956\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mf:\\artificial-intelegnce\\courses\\Learn LangChain In 1 Hour With End To End LLM Project With Deployment In Huggingface Spaces\\github\\LangchainEndtoEnd\\venv\\lib\\site-packages\\openai\\_base_client.py:993\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[39m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m    990\u001b[0m \u001b[39m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m    991\u001b[0m time\u001b[39m.\u001b[39msleep(timeout)\n\u001b[1;32m--> 993\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[0;32m    994\u001b[0m     options\u001b[39m=\u001b[39;49moptions,\n\u001b[0;32m    995\u001b[0m     cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[0;32m    996\u001b[0m     remaining_retries\u001b[39m=\u001b[39;49mremaining,\n\u001b[0;32m    997\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    998\u001b[0m     stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    999\u001b[0m )\n",
      "File \u001b[1;32mf:\\artificial-intelegnce\\courses\\Learn LangChain In 1 Hour With End To End LLM Project With Deployment In Huggingface Spaces\\github\\LangchainEndtoEnd\\venv\\lib\\site-packages\\openai\\_base_client.py:945\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    943\u001b[0m \u001b[39mif\u001b[39;00m retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_retry(err\u001b[39m.\u001b[39mresponse):\n\u001b[0;32m    944\u001b[0m     err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mclose()\n\u001b[1;32m--> 945\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retry_request(\n\u001b[0;32m    946\u001b[0m         options,\n\u001b[0;32m    947\u001b[0m         cast_to,\n\u001b[0;32m    948\u001b[0m         retries,\n\u001b[0;32m    949\u001b[0m         err\u001b[39m.\u001b[39;49mresponse\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    950\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    951\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    952\u001b[0m     )\n\u001b[0;32m    954\u001b[0m \u001b[39m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m    955\u001b[0m \u001b[39m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m    956\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mf:\\artificial-intelegnce\\courses\\Learn LangChain In 1 Hour With End To End LLM Project With Deployment In Huggingface Spaces\\github\\LangchainEndtoEnd\\venv\\lib\\site-packages\\openai\\_base_client.py:993\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[39m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m    990\u001b[0m \u001b[39m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m    991\u001b[0m time\u001b[39m.\u001b[39msleep(timeout)\n\u001b[1;32m--> 993\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[0;32m    994\u001b[0m     options\u001b[39m=\u001b[39;49moptions,\n\u001b[0;32m    995\u001b[0m     cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[0;32m    996\u001b[0m     remaining_retries\u001b[39m=\u001b[39;49mremaining,\n\u001b[0;32m    997\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    998\u001b[0m     stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    999\u001b[0m )\n",
      "    \u001b[1;31m[... skipping similar frames: SyncAPIClient._request at line 945 (7 times), SyncAPIClient._retry_request at line 993 (7 times)]\u001b[0m\n",
      "File \u001b[1;32mf:\\artificial-intelegnce\\courses\\Learn LangChain In 1 Hour With End To End LLM Project With Deployment In Huggingface Spaces\\github\\LangchainEndtoEnd\\venv\\lib\\site-packages\\openai\\_base_client.py:945\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    943\u001b[0m \u001b[39mif\u001b[39;00m retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_retry(err\u001b[39m.\u001b[39mresponse):\n\u001b[0;32m    944\u001b[0m     err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mclose()\n\u001b[1;32m--> 945\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retry_request(\n\u001b[0;32m    946\u001b[0m         options,\n\u001b[0;32m    947\u001b[0m         cast_to,\n\u001b[0;32m    948\u001b[0m         retries,\n\u001b[0;32m    949\u001b[0m         err\u001b[39m.\u001b[39;49mresponse\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    950\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    951\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    952\u001b[0m     )\n\u001b[0;32m    954\u001b[0m \u001b[39m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m    955\u001b[0m \u001b[39m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m    956\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mf:\\artificial-intelegnce\\courses\\Learn LangChain In 1 Hour With End To End LLM Project With Deployment In Huggingface Spaces\\github\\LangchainEndtoEnd\\venv\\lib\\site-packages\\openai\\_base_client.py:993\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[39m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m    990\u001b[0m \u001b[39m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m    991\u001b[0m time\u001b[39m.\u001b[39msleep(timeout)\n\u001b[1;32m--> 993\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[0;32m    994\u001b[0m     options\u001b[39m=\u001b[39;49moptions,\n\u001b[0;32m    995\u001b[0m     cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[0;32m    996\u001b[0m     remaining_retries\u001b[39m=\u001b[39;49mremaining,\n\u001b[0;32m    997\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    998\u001b[0m     stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    999\u001b[0m )\n",
      "File \u001b[1;32mf:\\artificial-intelegnce\\courses\\Learn LangChain In 1 Hour With End To End LLM Project With Deployment In Huggingface Spaces\\github\\LangchainEndtoEnd\\venv\\lib\\site-packages\\openai\\_base_client.py:960\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    957\u001b[0m         err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mread()\n\u001b[0;32m    959\u001b[0m     log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mRe-raising status error\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 960\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_status_error_from_response(err\u001b[39m.\u001b[39mresponse) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    962\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_response(\n\u001b[0;32m    963\u001b[0m     cast_to\u001b[39m=\u001b[39mcast_to,\n\u001b[0;32m    964\u001b[0m     options\u001b[39m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    967\u001b[0m     stream_cls\u001b[39m=\u001b[39mstream_cls,\n\u001b[0;32m    968\u001b[0m )\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "index = VectorStoreIndex.from_documents(documents, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index # incomplete"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
