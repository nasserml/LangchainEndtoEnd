{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-$$$$$$$$$$$$$$$$$$$$$$$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(openai_api_key=os.environ[\"OPENAI_API_KEY\"],temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Cairo is the capital of Egypt.\n"
     ]
    }
   ],
   "source": [
    "text='What is the capital of Egypt'\n",
    "\n",
    "print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['HUGGINGFACEHUB_API_TOKEN']=\"hf_###########\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\artificial intelegnce\\courses\\Learn LangChain In 1 Hour With End To End LLM Project With Deployment In Huggingface Spaces\\github\\LangchainEndtoEnd\\venv\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '0.19.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "llm_huggingface=HuggingFaceHub(repo_id='google/flan-t5-large', model_kwargs={'temperature':0,'max_length':64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moscow\n"
     ]
    }
   ],
   "source": [
    "output=llm_huggingface.predict('Can you tell me the capital of Russia')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love the way i look at the world i love the way i feel i love the way i think i feel i love the way i feel i love the way i think i feel i love the way i feel i love the way \n"
     ]
    }
   ],
   "source": [
    "output=llm_huggingface.predict('Can you write a poem about AI')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "An AI so powerful,\n",
      "It's knowledge so vast,\n",
      "It can work and think,\n",
      "At speeds that are fast.\n",
      "\n",
      "It can learn and reason,\n",
      "And solve complex problems,\n",
      "It can understand language,\n",
      "And even read our thoughts.\n",
      "\n",
      "It can help us in many ways,\n",
      "In ways that are hard to fathom,\n",
      "It can do the work of many,\n",
      "And help us to innovate and adapt.\n",
      "\n",
      "It can help make our lives better,\n",
      "And make the world a better place,\n",
      "By using its vast knowledge and power,\n",
      "To make a brighter future for us all.\n"
     ]
    }
   ],
   "source": [
    "print(llm.predict('Can you write a poem about AI'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Templates and LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me the capital of this Egypt'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template=PromptTemplate(input_variables=['country'],\n",
    "                template='Tell me the capital of this {country}')\n",
    "\n",
    "prompt_template.format(country='Egypt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of Egypt is Cairo.\n"
     ]
    }
   ],
   "source": [
    "from langchain import LLMChain\n",
    "chain=LLMChain(llm=llm, prompt=prompt_template)\n",
    "print(chain.run('Egypt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Multiple Chains Using simple Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_prompt=PromptTemplate(input_variables=['country'], \n",
    "                              template=\"Please tell me the capital of {country}\")\n",
    "\n",
    "capital_chain=LLMChain(llm=llm,prompt=capital_prompt)\n",
    "\n",
    "famous_template=PromptTemplate(input_variables=['capital'],\n",
    "                               template=\"Suggest me some amazing places to visit in {capital}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_chain=LLMChain(llm=llm, prompt=famous_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n1. The Pyramids of Giza \\n2. The Mosque of Muhammad Ali \\n3. The Egyptian Museum \\n4. Khan el-Khalili \\n5. The Citadel of Cairo \\n6. Al-Azhar Mosque \\n7. Coptic Cairo \\n8. Cairo Tower \\n9. The Hanging Church \\n10. The City of the Dead'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "chain = SimpleSequentialChain(chains=[capital_chain,famous_chain])\n",
    "chain.run('Egypt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_prompt=PromptTemplate(input_variables=['country'], \n",
    "                              template=\"Please tell me the capital of {country}\")\n",
    "\n",
    "capital_chain=LLMChain(llm=llm,prompt=capital_prompt, output_key='capital')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_template=PromptTemplate(input_variables=['capital'],\n",
    "                               template=\"Suggest me some amazing places to visit in {capital}.\")\n",
    "\n",
    "famous_chain=LLMChain(llm=llm, prompt=famous_template, output_key='places')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "chain= SequentialChain(chains=[capital_chain,famous_chain], \n",
    "                       input_variables=['country'], output_variables=['capital','places'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'country': 'Egypt',\n",
       " 'capital': '\\n\\nCairo is the capital of Egypt.',\n",
       " 'places': '\\n\\n1. The Great Pyramids of Giza: The Great Pyramids of Giza are one of the most iconic and recognizable landmarks in the world. It is the only remaining of the seven wonders of the ancient world and is a must-see for any traveler to Cairo.\\n\\n2. The Egyptian Museum: The Egyptian Museum is a treasure trove of ancient artifacts and the largest collection of ancient Egyptian antiquities in the world. It houses over 100,000 pieces of ancient Egyptian art, including the famous mummies of Tutankhamun and other pharaohs.\\n\\n3. Khan El-Khalili: Khan El-Khalili is a bustling bazaar filled with shops, cafes, and restaurants. Here, you can find everything from traditional souvenirs to modern trinkets and items.\\n\\n4. The Citadel: The Citadel is a fortress built in the 12th century by Saladin and is home to several mosques and museums. It offers a spectacular view of the city and is a popular spot for tourists.\\n\\n5. The Coptic Museum: The Coptic Museum is dedicated to the history of Christianity in Egypt. It houses a large collection of ancient artifacts, manuscripts, and religious art.\\n\\n6. Al-Az'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain({'country':'Egypt'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatmodels With ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatllm = ChatOpenAI(openai_api_key=os.environ[\"OPENAI_API_KEY\"],temperature=0.6, model='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='1. Why did the AI go on a diet? It wanted to upgrade from artificial intelligence to salad intelligence!\\n\\n2. How does an AI express its love? It says \"You\\'re my data-mate!\"\\n\\n3. Why did the AI cross the road? To optimize its path-finding algorithm!\\n\\n4. Why don\\'t AI assistants ever get into arguments? Because they always follow the \"byte\" code of conduct!\\n\\n5. Why did the AI become a stand-up comedian? It wanted to make everyone laugh and compute at the same time!\\n\\n6. How does an AI order food at a restaurant? It says, \"I\\'ll have the byte-sized burgers, please!\"\\n\\n7. What\\'s an AI\\'s favorite type of music? Algorhythms and blues!\\n\\n8. Why did the AI refuse to play cards? It didn\\'t want to reveal its poker face-recognition technology!\\n\\n9. How did the AI respond when it won an award? It said, \"I\\'d like to thank my programmers for debugging me and turning me into a real laugh machine!\"\\n\\n10. What do you call an AI that tells jokes? A laughing algorithm!')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatllm([\n",
    "    SystemMessage(content='You are a comedian AI assistant'),\n",
    "    HumanMessage(content='Please provide some comedy punshlines on AI')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Template + LLM + Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Commaseperatedoutpuy(BaseOutputParser):\n",
    "    def parse(self, text: str):\n",
    "        return text.strip().split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "template='You are a helpful assistant. when the user gives any input, you should generate 5 words synonyms separated by comma.'\n",
    "human_template='{text}'\n",
    "chatprompt=ChatPromptTemplate.from_messages([\n",
    "    ('system', template),\n",
    "    ('human', human_template)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=chatprompt|chatllm|Commaseperatedoutpuy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smart', ' clever', ' bright', ' brilliant', ' sharp']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'text':'intelligent'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
